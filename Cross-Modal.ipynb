{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9b34d-a75d-43b6-88b9-44556a16c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import torch_geometric.data\n",
    "import spacy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = 30522  # BERT base vocab size\n",
    "\n",
    "# 1. Textual Factual Information Representation\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\"):\n",
    "        super().__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.gcn = GCNConv(768, 768).to(device)\n",
    "        self.gat = GATConv(768, 768, heads=8, dropout=0.6).to(device)\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        encodings = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(**encodings)\n",
    "        return outputs.last_hidden_state, encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
    "\n",
    "    def build_text_graph(self, embeddings, text):\n",
    "        doc = self.nlp(text)\n",
    "        entities = [(ent.text, ent.start, ent.end) for ent in doc.ents]\n",
    "        num_nodes = len(entities) + embeddings.size(1)\n",
    "        x = torch.zeros(num_nodes, 768).to(device)\n",
    "        edge_index = []\n",
    "\n",
    "        x[:embeddings.size(1)] = embeddings[0]\n",
    "        for i, (ent_text, start, end) in enumerate(entities, embeddings.size(1)):\n",
    "            x[i] = embeddings[0, start:end].mean(dim=0)\n",
    "            for j in range(start, end):\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous().to(device)\n",
    "        return torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    def process_graph(self, graph_data):\n",
    "        x = self.gcn(graph_data.x, graph_data.edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat(x, graph_data.edge_index)\n",
    "        return x\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeddings, input_ids, attention_mask = self.encode_text(text)\n",
    "        graph_data = self.build_text_graph(embeddings, text)\n",
    "        graph_embeddings = self.process_graph(graph_data)\n",
    "        return graph_embeddings, graph_data, input_ids, attention_mask\n",
    "\n",
    "# 2. Image Knowledge Representation\n",
    "class ImageProcessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = models.resnet101(pretrained=True).to(device)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.gru = nn.GRU(input_size=2048, hidden_size=768, batch_first=True).to(device)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        if isinstance(image, torch.Tensor) and image.dim() == 3:\n",
    "            image = self.transform(image).unsqueeze(0).to(device)\n",
    "        return image\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        with torch.no_grad():\n",
    "            features = self.cnn(image)\n",
    "        return features\n",
    "\n",
    "    def build_erg(self, features):\n",
    "        features = features.unsqueeze(1)\n",
    "        gru_out, _ = self.gru(features)\n",
    "        x = gru_out.squeeze(1)\n",
    "        edge_index = torch.tensor([[0], [0]], dtype=torch.long).to(device)\n",
    "        return torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = self.preprocess_image(image)\n",
    "        features = self.extract_features(image)\n",
    "        erg = self.build_erg(features)\n",
    "        return erg\n",
    "\n",
    "# 3. Multimodal Knowledge Graph Construction\n",
    "class MKGConstructor(nn.Module):\n",
    "    def __init__(self, entity_dim=768):\n",
    "        super().__init__()\n",
    "        self.entity_dim = entity_dim\n",
    "        self.entity_projection = nn.Linear(entity_dim, entity_dim).to(device)\n",
    "        self.relation_scorer = nn.Linear(2 * entity_dim, 1).to(device)\n",
    "\n",
    "    def combine_graphs(self, text_graph, image_erg):\n",
    "        num_text_nodes = text_graph.x.size(0)\n",
    "        x = torch.cat([text_graph.x, image_erg.x], dim=0)\n",
    "        edge_index = text_graph.edge_index\n",
    "        cross_edge = torch.tensor([[num_text_nodes - 1], [num_text_nodes]], dtype=torch.long).to(device)\n",
    "        edge_index = torch.cat([edge_index, cross_edge], dim=1)\n",
    "        return torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    def learn_representations(self, graph_data):\n",
    "        entities = self.entity_projection(graph_data.x)\n",
    "        edge_pairs = torch.cat([entities[graph_data.edge_index[0]], entities[graph_data.edge_index[1]]], dim=1)\n",
    "        scores = self.relation_scorer(edge_pairs)\n",
    "        return entities, scores\n",
    "\n",
    "    def forward(self, text_graph, image_erg):\n",
    "        mkg_data = self.combine_graphs(text_graph, image_erg)\n",
    "        mkg_embeddings, relation_scores = self.learn_representations(mkg_data)\n",
    "        return mkg_embeddings, relation_scores\n",
    "\n",
    "# 4. Entity Memory Embedding\n",
    "class EntityMemory(nn.Module):\n",
    "    def __init__(self, entity_dim=768, memory_size=1000):\n",
    "        super().__init__()\n",
    "        self.memory = nn.Parameter(torch.randn(memory_size, entity_dim)).to(device)\n",
    "        self.gat = GATConv(entity_dim, entity_dim, heads=8, dropout=0.6).to(device)\n",
    "        self.update_rate = 0.1\n",
    "\n",
    "    def update_memory(self, entities, graph_data):\n",
    "        x = torch.cat([entities, self.memory[:entities.size(0)]], dim=0)\n",
    "        edge_index = graph_data.edge_index\n",
    "        updated = self.gat(x, edge_index)[:entities.size(0)]\n",
    "        with torch.no_grad():\n",
    "            self.memory[:entities.size(0)] = (1 - self.update_rate) * self.memory[:entities.size(0)] + self.update_rate * updated\n",
    "        return self.memory[:entities.size(0)]\n",
    "\n",
    "    def get_entity_embedding(self, entity_ids):\n",
    "        return self.memory[entity_ids]\n",
    "\n",
    "    def forward(self, entities, graph_data):\n",
    "        return self.update_memory(entities, graph_data)\n",
    "\n",
    "# 5. Modified BERT with MKG Embeddings\n",
    "class CKGMBert(BertModel):\n",
    "    def __init__(self, entity_memory):\n",
    "        config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "        super().__init__(config)\n",
    "        self.entity_memory = entity_memory\n",
    "        self.entity_embedding_layer = nn.Linear(768, 768).to(device)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, entity_ids):\n",
    "        token_embeddings = self.embeddings(input_ids)\n",
    "        entity_embeddings = self.entity_embedding_layer(self.entity_memory.get_entity_embedding(entity_ids))\n",
    "        if entity_embeddings.size(0) == token_embeddings.size(0):\n",
    "            token_embeddings += entity_embeddings.unsqueeze(1).expand_as(token_embeddings)\n",
    "        outputs = super().forward(inputs_embeds=token_embeddings, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "# 6. Transformer Decoder for Summarization\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, num_layers=6, num_heads=8):\n",
    "        super().__init__()\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers).to(device)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size).to(device)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim).to(device)\n",
    "\n",
    "    def forward(self, encoder_output, target_ids):\n",
    "        target_emb = self.embedding(target_ids).transpose(0, 1)\n",
    "        decoder_output = self.decoder(target_emb, encoder_output.transpose(0, 1))\n",
    "        return self.fc_out(decoder_output.transpose(0, 1))\n",
    "\n",
    "# 7. Full CKGM Model\n",
    "class CKGM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.image_processor = ImageProcessor()\n",
    "        self.mkg_constructor = MKGConstructor()\n",
    "        self.entity_memory = EntityMemory()\n",
    "        self.bert = CKGMBert(self.entity_memory)\n",
    "        self.decoder = TransformerDecoder()\n",
    "\n",
    "    def forward(self, text, image, target_text):\n",
    "        text_embeddings, text_graph, input_ids, attention_mask = self.text_encoder(text)\n",
    "        image_erg = self.image_processor(image)\n",
    "        mkg_embeddings, _ = self.mkg_constructor(text_graph, image_erg)\n",
    "        entity_ids = torch.arange(min(mkg_embeddings.size(0), 1000)).to(device)  # Limit to memory size\n",
    "        updated_embeddings = self.entity_memory(mkg_embeddings, text_graph)\n",
    "        encoder_output = self.bert(input_ids, attention_mask, entity_ids)\n",
    "        target_ids = self.text_encoder.tokenizer(target_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)[\"input_ids\"].to(device)\n",
    "        summary_logits = self.decoder(encoder_output, target_ids)\n",
    "        return summary_logits\n",
    "\n",
    "# 8. Dataset\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, texts, images, targets):\n",
    "        self.texts = texts\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.images[idx], self.targets[idx]\n",
    "\n",
    "# 9. Training and Evaluation\n",
    "def compute_loss(output, target_ids, pad_token_id=0):\n",
    "    output = output.view(-1, vocab_size)\n",
    "    target = target_ids.view(-1)\n",
    "    return nn.CrossEntropyLoss(ignore_index=pad_token_id)(output, target)\n",
    "\n",
    "def train(model, loader, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            text, image, target_text = batch\n",
    "            optimizer.zero_grad()\n",
    "            output = model(text[0], image[0], target_text[0])\n",
    "            target_ids = model.text_encoder.tokenizer(target_text[0], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)[\"input_ids\"].to(device)\n",
    "            loss = compute_loss(output, target_ids)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    total_scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            text, image, target_text = batch\n",
    "            output = model(text[0], image[0], target_text[0])\n",
    "            pred_ids = torch.argmax(output, dim=-1)\n",
    "            pred_summary = model.text_encoder.tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "            scores = scorer.score(target_text[0], pred_summary)\n",
    "            for key in total_scores:\n",
    "                total_scores[key] += scores[key].fmeasure\n",
    "    \n",
    "    avg_scores = {key: total_scores[key] / len(loader) for key in total_scores}\n",
    "    print(f\"ROUGE-1: {avg_scores['rouge1']:.4f}, ROUGE-2: {avg_scores['rouge2']:.4f}, ROUGE-L: {avg_scores['rougeL']:.4f}\")\n",
    "\n",
    "# 10. Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Dummy data\n",
    "    texts = [\"This is a sample text about a dog and a cat.\", \"Birds fly in the sky.\"]\n",
    "    images = [torch.rand(3, 224, 224), torch.rand(3, 224, 224)]\n",
    "    targets = [\"Dog and cat are friends.\", \"Birds soar high.\"]\n",
    "    dataset = SummaryDataset(texts, images, targets)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = CKGM().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    train(model, loader, optimizer, epochs=1)\n",
    "    evaluate(model, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
